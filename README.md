## microvid
A tiny **video generation** model with a [**microdiffusion-type**](https://arxiv.org/abs/2407.15811) architecture.

Dataset used => [**tensorkelechi/tiny_webvid_latents**](https://huggingface.co/datasets/tensorkelechi/tiny_webvid_latents) (this is for testing, will process a larger one with more compute)

### credits
* [**Microdiffusion**](https://arxiv.org/abs/2407.15811) => research paper.
* [**SwayStar123/microdiffusion**](https://github.com/SwayStar123/microdiffusion) => MicroDiT implementation for images (pytorch, unofficial but works)
* [**mochi-1**](https://github.com/genmoai/mochi) and [**HunyuanVideo**](https://github.com/Tencent/HunyuanVideo/) => adapted video-specific stuff from their codebases